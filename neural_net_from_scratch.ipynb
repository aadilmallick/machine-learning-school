{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00733c1-9fef-42a4-8bb2-a15aa4c2a436",
   "metadata": {},
   "source": [
    "# Neural Net from scratch\n",
    "\n",
    "Go here for more info: https://github.com/DataScienceHamburg/PyTorchUltimateMaterial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c54320-154c-477f-b526-f9cadbf616d3",
   "metadata": {},
   "source": [
    "## Creating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84ae537-32a6-4a8a-8cbb-bb53312a5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a77cd8-ca84-499f-a933-c7b997ff2460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bb6335-1a26-4fb5-87bd-37c179be65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"output\"])\n",
    "y = df[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217b7fc5-f11a-4fbc-8afd-82d8263071b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the data according to training data, and set mean and standard deviation for train data\n",
    "# scaler.fit(X) : fits data according to dataset (calculates mean and standard deviation)\n",
    "# scaler.transform(X) : transforms dataset according to its previously set parameters (mean and standard deviation)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# scale according to training data, do not fit scaler to test data since we want to avoid bias.  \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ca0bc-5e46-419b-a01d-2a7958fd2129",
   "metadata": {},
   "source": [
    "## Creating the class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a39dc72e-dbc1-4a8c-b2b2-8df55eaf38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, alpha = 0.1):\n",
    "        self.X = X.T\n",
    "        self.y = y\n",
    "        self.alpha = alpha\n",
    "\n",
    "        input_layer_size = self.X.shape[0]\n",
    "        \n",
    "        # layer sizes\n",
    "        self.n = [self.X.shape[0], 4, 1]\n",
    "\n",
    "        # two layers\n",
    "        self.L = 2 \n",
    "\n",
    "        # 1. create weights\n",
    "        # size should be n[l] x n[L-1]\n",
    "        W1 = np.random.randn(self.n[1], self.n[0]) * 0.1 \n",
    "        W2 = np.random.randn(self.n[2], self.n[1]) * 0.1\n",
    "        self.W = {\n",
    "            \"1\": W1,\n",
    "            \"2\": W2\n",
    "        }\n",
    "\n",
    "        # 2. create bias, initialize to 0\n",
    "        # size should be n[l] x 1 for column vector\n",
    "        b1 = np.random.randn(self.n[1], 1)\n",
    "        b2 = np.random.randn(self.n[2], 1)\n",
    "        self.b = {\n",
    "            \"1\": b1,\n",
    "            \"2\": b2\n",
    "        }\n",
    "\n",
    "        # 3. create gradient cache\n",
    "        self.cache = {\n",
    "            \"A1\": None,\n",
    "            \"Z2\": None,\n",
    "        }\n",
    "\n",
    "    def output_shape(self):\n",
    "        print(f\"Weights for layer 1 shape: {self.W['1'].shape}\")\n",
    "        print(f\"Weights for layer 2 shape: {self.W['2'].shape}\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def g(arr) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-arr))\n",
    "\n",
    "    @staticmethod\n",
    "    def gprime(y_hat) -> np.ndarray:\n",
    "        return y_hat * (1 - y_hat)\n",
    "\n",
    "    # vectorized implementation of feed forward\n",
    "    def forward(self, X):\n",
    "        m = X.shape[1]\n",
    "        Z1 = self.W['1'] @ X + self.b['1']\n",
    "        assert Z1.shape == (self.n[1], m)\n",
    "        \n",
    "        A1 = NeuralNet.g(Z1)\n",
    "        self.cache[\"A1\"] = A1\n",
    "        \n",
    "        Z2 = self.W['2'] @ A1 + self.b['2']\n",
    "        self.cache[\"Z2\"] = Z2\n",
    "        assert Z2.shape == (self.n[2], m)\n",
    "        \n",
    "        A2 = NeuralNet.g(Z2)\n",
    "        \n",
    "        y_hat = A2\n",
    "        return y_hat\n",
    "\n",
    "    # using mean squared error as loss\n",
    "    @staticmethod\n",
    "    def loss(y_hat, y):\n",
    "        return (y_hat.reshape(-1) - y.reshape(-1)) ** 2\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(y_hat, y):\n",
    "        m = y_hat.reshape(-1).shape[0]\n",
    "        return np.sum(NeuralNet.loss(y_hat, y)) / m\n",
    "        \n",
    "\n",
    "    # vectorized implementation of feed forward\n",
    "    def backward(self, y_hat, y):\n",
    "        m = y_hat.reshape(-1).shape[0]\n",
    "\n",
    "        \"\"\"\n",
    "        Layer 2 calculations\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        A2 = y_hat.reshape(1 , -1)\n",
    "        pred = y.reshape(1 , -1)\n",
    "\n",
    "\n",
    "        # 1. calculate dCdZ2, which lets you get dCdW2, dCdb1, and dCdA1 for next propagation\n",
    "        \n",
    "        dCdA2 = (1 / m)  * 2 * (A2 - pred)\n",
    "        assert dCdA2.shape == (1, m), \"something went wrong\"\n",
    "\n",
    "        dA2dZ2 = A2 * (1 - A2)\n",
    "        assert dA2dZ2.shape == ( self.n[2] ,m) , f\"shape is {dA2dZ2.shape}\"\n",
    "\n",
    "        dC_dZ2 = (dCdA2 * dA2dZ2)\n",
    "        assert dC_dZ2.shape == (self.n[2] , m), f\"shape mismatch {dC_dZ2.shape}\"\n",
    "        \n",
    "        # 2. calculate dCdW2\n",
    "        \n",
    "        dZ2W2 = self.cache[\"A1\"]\n",
    "        assert dC_dZ2.shape == (self.n[2], m), f\"shape mismatch {dC_dZ2.shape}\"\n",
    "        \n",
    "        gradW2 = dC_dZ2 @ dZ2W2.T\n",
    "        assert gradW2.shape == self.W['2'].shape\n",
    "\n",
    "        # 3. calculate dbdW2\n",
    "        \n",
    "        gradb2 = np.sum( dC_dZ2, axis=1 ).reshape(self.n[2], 1)\n",
    "        assert gradb2.shape == (self.n[2], 1)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Layer 1 calculations\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # 1. with dC/dZ2 stored, calculate dC/dZ1 = dC/dZ2 * dZ2/dA1 * dA1/dZ1\n",
    "        \n",
    "        dZ2_dA1 = self.W['2']\n",
    "\n",
    "        A1 = self.cache[\"A1\"]\n",
    "        dA1_dZ1 = A1 * (1 - A1)\n",
    "        assert dA1_dZ1.shape == (self.n[1] , m), f\"shape mismatch {dA1_dZ1.shape}\"\n",
    "\n",
    "\n",
    "        dC_dZ1 = (self.W['2'].T @ dC_dZ2) * dA1_dZ1\n",
    "        assert dC_dZ1.shape == (self.n[1] , m), f\"shape mismatch {dC_dZ1.shape}\"\n",
    "\n",
    "        # 2. calculate dC/dW1 = dC/dZ1 * dZ1/dW1\n",
    "        \n",
    "        dZ1_dW1 = self.X\n",
    "        gradW1 = dC_dZ1 @ dZ1_dW1.T\n",
    "        assert gradW1.shape == self.W['1'].shape, f\"gradient shape mismatch\"\n",
    "        \n",
    "        # 3. calculate dC/db1 = dC/dZ1 * dZ1/db1\n",
    "        \n",
    "        gradb1 = np.sum(  dC_dZ1, axis=1 ).reshape(self.n[1], 1)\n",
    "\n",
    "        return {\n",
    "            \"gradW2\" : gradW2,\n",
    "            \"gradb2\" : gradb2,\n",
    "            \"gradW1\" : gradW1,\n",
    "            \"gradb1\" : gradb1\n",
    "        }\n",
    "\n",
    "    def train(self, epochs = 1000):\n",
    "        costs = []\n",
    "        for e in range(epochs):\n",
    "            # 1. hypothesis\n",
    "            y_hat = self.forward(self.X)\n",
    "\n",
    "            # 2. calculate cost\n",
    "            cost = NeuralNet.cost(y_hat, self.y)\n",
    "            costs.append(cost)\n",
    "\n",
    "            # 3. backprop\n",
    "            grads = self.backward(y_hat, self.y)\n",
    "\n",
    "            # 4. update parameters\n",
    "            self.W['2'] += -self.alpha * grads['gradW2']\n",
    "            self.W['1'] += -self.alpha * grads['gradW1']\n",
    "            \n",
    "            self.b['2'] += -self.alpha * grads['gradb2']\n",
    "            self.b['1'] += -self.alpha * grads['gradb1']\n",
    "\n",
    "            if e % 20 == 0:\n",
    "                print(f\"epoch {e}: cost is {cost}\")\n",
    "\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "305e2a23-6d23-43bd-aede-d57839d7520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost is 0.24798824835527614\n",
      "epoch 20: cost is 0.24706891532317807\n",
      "epoch 40: cost is 0.24642399055839986\n",
      "epoch 60: cost is 0.24584428507390044\n",
      "epoch 80: cost is 0.24523923010584694\n",
      "epoch 100: cost is 0.2445617742455527\n",
      "epoch 120: cost is 0.24377911186046994\n",
      "epoch 140: cost is 0.24286156293121022\n",
      "epoch 160: cost is 0.24177835564554961\n",
      "epoch 180: cost is 0.24049606668927756\n",
      "epoch 200: cost is 0.23897821639907085\n",
      "epoch 220: cost is 0.23718555667026198\n",
      "epoch 240: cost is 0.23507698189118975\n",
      "epoch 260: cost is 0.23261113411419013\n",
      "epoch 280: cost is 0.22974880003943157\n",
      "epoch 300: cost is 0.2264561480164111\n",
      "epoch 320: cost is 0.2227087343511064\n",
      "epoch 340: cost is 0.21849602204622073\n",
      "epoch 360: cost is 0.2138259149167097\n",
      "epoch 380: cost is 0.20872855071350352\n",
      "epoch 400: cost is 0.20325838918034406\n",
      "epoch 420: cost is 0.19749359687846108\n",
      "epoch 440: cost is 0.19153202836355468\n",
      "epoch 460: cost is 0.1854838283671463\n",
      "epoch 480: cost is 0.17946169606209714\n",
      "epoch 500: cost is 0.17357072558395126\n",
      "epoch 520: cost is 0.16789995905394167\n",
      "epoch 540: cost is 0.16251718459631004\n",
      "epoch 560: cost is 0.1574674133038546\n",
      "epoch 580: cost is 0.15277444741839538\n",
      "epoch 600: cost is 0.14844440296565622\n",
      "epoch 620: cost is 0.14447001614437532\n",
      "epoch 640: cost is 0.14083484886699002\n",
      "epoch 660: cost is 0.13751688427655834\n",
      "epoch 680: cost is 0.13449131964233316\n",
      "epoch 700: cost is 0.13173256997700558\n",
      "epoch 720: cost is 0.12921559974727265\n",
      "epoch 740: cost is 0.12691673332630243\n",
      "epoch 760: cost is 0.12481408831942184\n",
      "epoch 780: cost is 0.12288775194717898\n",
      "epoch 800: cost is 0.12111979257305708\n",
      "epoch 820: cost is 0.11949417277201235\n",
      "epoch 840: cost is 0.11799660949016516\n",
      "epoch 860: cost is 0.11661441112602834\n",
      "epoch 880: cost is 0.11533631010946468\n",
      "epoch 900: cost is 0.11415230182644837\n",
      "epoch 920: cost is 0.11305349562813852\n",
      "epoch 940: cost is 0.11203198041466825\n",
      "epoch 960: cost is 0.1110807053135723\n",
      "epoch 980: cost is 0.11019337485175074\n",
      "epoch 1000: cost is 0.1093643574454869\n",
      "epoch 1020: cost is 0.10858860579743074\n",
      "epoch 1040: cost is 0.10786158775379104\n",
      "epoch 1060: cost is 0.10717922624913533\n",
      "epoch 1080: cost is 0.1065378470935661\n",
      "epoch 1100: cost is 0.10593413350350481\n",
      "epoch 1120: cost is 0.10536508642344021\n",
      "epoch 1140: cost is 0.10482798982167274\n",
      "epoch 1160: cost is 0.10432038026388328\n",
      "epoch 1180: cost is 0.10384002017315165\n",
      "epoch 1200: cost is 0.10338487427449931\n",
      "epoch 1220: cost is 0.10295308879764065\n",
      "epoch 1240: cost is 0.10254297307520009\n",
      "epoch 1260: cost is 0.10215298322698514\n",
      "epoch 1280: cost is 0.10178170766565305\n",
      "epoch 1300: cost is 0.10142785419670554\n",
      "epoch 1320: cost is 0.10109023851741518\n",
      "epoch 1340: cost is 0.10076777394604004\n",
      "epoch 1360: cost is 0.10045946223535922\n",
      "epoch 1380: cost is 0.1001643853438447\n",
      "epoch 1400: cost is 0.09988169805423429\n",
      "epoch 1420: cost is 0.0996106213433495\n",
      "epoch 1440: cost is 0.09935043641908407\n",
      "epoch 1460: cost is 0.09910047935088995\n",
      "epoch 1480: cost is 0.09886013622906194\n",
      "epoch 1500: cost is 0.09862883879588764\n",
      "epoch 1520: cost is 0.09840606049846376\n",
      "epoch 1540: cost is 0.09819131291883286\n",
      "epoch 1560: cost is 0.09798414254219696\n",
      "epoch 1580: cost is 0.09778412782841563\n",
      "epoch 1600: cost is 0.09759087655589535\n",
      "epoch 1620: cost is 0.09740402341039264\n",
      "epoch 1640: cost is 0.09722322779425707\n",
      "epoch 1660: cost is 0.09704817183428305\n",
      "epoch 1680: cost is 0.09687855856867203\n",
      "epoch 1700: cost is 0.09671411029566618\n",
      "epoch 1720: cost is 0.0965545670682398\n",
      "epoch 1740: cost is 0.09639968532085144\n",
      "epoch 1760: cost is 0.09624923661569713\n",
      "epoch 1780: cost is 0.09610300649718195\n",
      "epoch 1800: cost is 0.09596079344446616\n",
      "epoch 1820: cost is 0.09582240791295654\n",
      "epoch 1840: cost is 0.09568767145652073\n",
      "epoch 1860: cost is 0.09555641592301214\n",
      "epoch 1880: cost is 0.0954284827164185\n",
      "epoch 1900: cost is 0.09530372211959706\n",
      "epoch 1920: cost is 0.09518199267214171\n",
      "epoch 1940: cost is 0.09506316059845019\n",
      "epoch 1960: cost is 0.09494709928152965\n",
      "epoch 1980: cost is 0.09483368877850012\n",
      "epoch 2000: cost is 0.09472281537413596\n",
      "epoch 2020: cost is 0.09461437116912624\n",
      "epoch 2040: cost is 0.09450825370004426\n",
      "epoch 2060: cost is 0.09440436558829164\n",
      "epoch 2080: cost is 0.09430261421553497\n",
      "epoch 2100: cost is 0.09420291142337697\n",
      "epoch 2120: cost is 0.09410517323520896\n",
      "epoch 2140: cost is 0.09400931959837469\n",
      "epoch 2160: cost is 0.09391527414494313\n",
      "epoch 2180: cost is 0.09382296396953704\n",
      "epoch 2200: cost is 0.09373231942280116\n",
      "epoch 2220: cost is 0.09364327391921727\n",
      "epoch 2240: cost is 0.09355576375808428\n",
      "epoch 2260: cost is 0.09346972795658394\n",
      "epoch 2280: cost is 0.09338510809394379\n",
      "epoch 2300: cost is 0.09330184816579266\n",
      "epoch 2320: cost is 0.09321989444788051\n",
      "epoch 2340: cost is 0.09313919536840232\n",
      "epoch 2360: cost is 0.09305970138822967\n",
      "epoch 2380: cost is 0.0929813648884096\n",
      "epoch 2400: cost is 0.09290414006434439\n",
      "epoch 2420: cost is 0.09282798282611111\n",
      "epoch 2440: cost is 0.09275285070442629\n",
      "epoch 2460: cost is 0.09267870276179832\n",
      "epoch 2480: cost is 0.09260549950844894\n",
      "epoch 2500: cost is 0.09253320282261734\n",
      "epoch 2520: cost is 0.09246177587489272\n",
      "epoch 2540: cost is 0.0923911830562486\n",
      "epoch 2560: cost is 0.09232138990947944\n",
      "epoch 2580: cost is 0.0922523630637643\n",
      "epoch 2600: cost is 0.09218407017210542\n",
      "epoch 2620: cost is 0.09211647985141017\n",
      "epoch 2640: cost is 0.09204956162500535\n",
      "epoch 2660: cost is 0.09198328586739137\n",
      "epoch 2680: cost is 0.09191762375106115\n",
      "epoch 2700: cost is 0.09185254719522497\n",
      "epoch 2720: cost is 0.09178802881629916\n",
      "epoch 2740: cost is 0.09172404188003029\n",
      "epoch 2760: cost is 0.09166056025514195\n",
      "epoch 2780: cost is 0.09159755836840418\n",
      "epoch 2800: cost is 0.09153501116103972\n",
      "epoch 2820: cost is 0.09147289404639339\n",
      "epoch 2840: cost is 0.09141118286880451\n",
      "epoch 2860: cost is 0.09134985386363378\n",
      "epoch 2880: cost is 0.09128888361840916\n",
      "epoch 2900: cost is 0.09122824903506657\n",
      "epoch 2920: cost is 0.09116792729327454\n",
      "epoch 2940: cost is 0.09110789581484269\n",
      "epoch 2960: cost is 0.09104813222922754\n",
      "epoch 2980: cost is 0.09098861434016053\n",
      "epoch 3000: cost is 0.09092932009343588\n",
      "epoch 3020: cost is 0.09087022754590919\n",
      "epoch 3040: cost is 0.09081131483576955\n",
      "epoch 3060: cost is 0.09075256015416205\n",
      "epoch 3080: cost is 0.09069394171825007\n",
      "epoch 3100: cost is 0.09063543774582124\n",
      "epoch 3120: cost is 0.09057702643155319\n",
      "epoch 3140: cost is 0.09051868592507054\n",
      "epoch 3160: cost is 0.09046039431093704\n",
      "epoch 3180: cost is 0.09040212959074065\n",
      "epoch 3200: cost is 0.09034386966744297\n",
      "epoch 3220: cost is 0.09028559233217658\n",
      "epoch 3240: cost is 0.09022727525368585\n",
      "epoch 3260: cost is 0.09016889597061811\n",
      "epoch 3280: cost is 0.09011043188688064\n",
      "epoch 3300: cost is 0.09005186027028773\n",
      "epoch 3320: cost is 0.08999315825472656\n",
      "epoch 3340: cost is 0.08993430284607433\n",
      "epoch 3360: cost is 0.08987527093209809\n",
      "epoch 3380: cost is 0.08981603929656479\n",
      "epoch 3400: cost is 0.08975658463778141\n",
      "epoch 3420: cost is 0.08969688359177046\n",
      "epoch 3440: cost is 0.08963691276026899\n",
      "epoch 3460: cost is 0.08957664874371371\n",
      "epoch 3480: cost is 0.08951606817934381\n",
      "epoch 3500: cost is 0.08945514778451578\n",
      "epoch 3520: cost is 0.08939386440527856\n",
      "epoch 3540: cost is 0.08933219507020548\n",
      "epoch 3560: cost is 0.08927011704941928\n",
      "epoch 3580: cost is 0.08920760791867964\n",
      "epoch 3600: cost is 0.08914464562832912\n",
      "epoch 3620: cost is 0.08908120857681294\n",
      "epoch 3640: cost is 0.08901727568840423\n",
      "epoch 3660: cost is 0.08895282649467699\n",
      "epoch 3680: cost is 0.08888784121917892\n",
      "epoch 3700: cost is 0.08882230086466462\n",
      "epoch 3720: cost is 0.08875618730216082\n",
      "epoch 3740: cost is 0.08868948336105008\n",
      "epoch 3760: cost is 0.08862217291928097\n",
      "epoch 3780: cost is 0.08855424099274427\n",
      "epoch 3800: cost is 0.0884856738227967\n",
      "epoch 3820: cost is 0.08841645896087251\n",
      "epoch 3840: cost is 0.08834658534909694\n",
      "epoch 3860: cost is 0.08827604339580986\n",
      "epoch 3880: cost is 0.08820482504492146\n",
      "epoch 3900: cost is 0.08813292383805894\n",
      "epoch 3920: cost is 0.08806033496852106\n",
      "epoch 3940: cost is 0.08798705532613861\n",
      "epoch 3960: cost is 0.08791308353224107\n",
      "epoch 3980: cost is 0.08783841996405174\n",
      "epoch 4000: cost is 0.08776306676797374\n",
      "epoch 4020: cost is 0.08768702786138277\n",
      "epoch 4040: cost is 0.08761030892270835\n",
      "epoch 4060: cost is 0.08753291736975798\n",
      "epoch 4080: cost is 0.0874548623264129\n",
      "epoch 4100: cost is 0.08737615457799898\n",
      "epoch 4120: cost is 0.08729680651580296\n",
      "epoch 4140: cost is 0.0872168320713621\n",
      "epoch 4160: cost is 0.08713624664129874\n",
      "epoch 4180: cost is 0.08705506700359651\n",
      "epoch 4200: cost is 0.08697331122632151\n",
      "epoch 4220: cost is 0.08689099856987414\n",
      "epoch 4240: cost is 0.08680814938391769\n",
      "epoch 4260: cost is 0.08672478500016548\n",
      "epoch 4280: cost is 0.08664092762221937\n",
      "epoch 4300: cost is 0.0865566002136423\n",
      "epoch 4320: cost is 0.08647182638541427\n",
      "epoch 4340: cost is 0.08638663028386892\n",
      "epoch 4360: cost is 0.08630103648013998\n",
      "epoch 4380: cost is 0.08621506986206366\n",
      "epoch 4400: cost is 0.08612875552938842\n",
      "epoch 4420: cost is 0.0860421186930434\n",
      "epoch 4440: cost is 0.08595518457910821\n",
      "epoch 4460: cost is 0.0858679783380188\n",
      "epoch 4480: cost is 0.08578052495943517\n",
      "epoch 4500: cost is 0.08569284919309036\n",
      "epoch 4520: cost is 0.08560497547583978\n",
      "epoch 4540: cost is 0.08551692786503443\n",
      "epoch 4560: cost is 0.08542872997825475\n",
      "epoch 4580: cost is 0.08534040493936343\n",
      "epoch 4600: cost is 0.0852519753307658\n",
      "epoch 4620: cost is 0.08516346315170738\n",
      "epoch 4640: cost is 0.08507488978238668\n",
      "epoch 4660: cost is 0.08498627595362175\n",
      "epoch 4680: cost is 0.08489764172177577\n",
      "epoch 4700: cost is 0.08480900644862399\n",
      "epoch 4720: cost is 0.08472038878582767\n",
      "epoch 4740: cost is 0.0846318066636721\n",
      "epoch 4760: cost is 0.08454327728372238\n",
      "epoch 4780: cost is 0.08445481711505314\n",
      "epoch 4800: cost is 0.08436644189371445\n",
      "epoch 4820: cost is 0.08427816662510837\n",
      "epoch 4840: cost is 0.08419000558896196\n",
      "epoch 4860: cost is 0.0841019723465999\n",
      "epoch 4880: cost is 0.08401407975023686\n",
      "epoch 4900: cost is 0.08392633995402816\n",
      "epoch 4920: cost is 0.0838387644266371\n",
      "epoch 4940: cost is 0.08375136396509586\n",
      "epoch 4960: cost is 0.0836641487097575\n",
      "epoch 4980: cost is 0.08357712816015432\n",
      "epoch 5000: cost is 0.08349031119159704\n",
      "epoch 5020: cost is 0.08340370607236566\n",
      "epoch 5040: cost is 0.08331732048136081\n",
      "epoch 5060: cost is 0.08323116152609808\n",
      "epoch 5080: cost is 0.08314523576094364\n",
      "epoch 5100: cost is 0.08305954920550124\n",
      "epoch 5120: cost is 0.08297410736307391\n",
      "epoch 5140: cost is 0.08288891523913351\n",
      "epoch 5160: cost is 0.08280397735974135\n",
      "epoch 5180: cost is 0.08271929778987239\n",
      "epoch 5200: cost is 0.08263488015160207\n",
      "epoch 5220: cost is 0.0825507276421225\n",
      "epoch 5240: cost is 0.08246684305156073\n",
      "epoch 5260: cost is 0.08238322878057594\n",
      "epoch 5280: cost is 0.08229988685771804\n",
      "epoch 5300: cost is 0.08221681895653311\n",
      "epoch 5320: cost is 0.08213402641240453\n",
      "epoch 5340: cost is 0.08205151023912129\n",
      "epoch 5360: cost is 0.08196927114516746\n",
      "epoch 5380: cost is 0.0818873095497276\n",
      "epoch 5400: cost is 0.08180562559840557\n",
      "epoch 5420: cost is 0.08172421917865434\n",
      "epoch 5440: cost is 0.08164308993491547\n",
      "epoch 5460: cost is 0.08156223728346777\n",
      "epoch 5480: cost is 0.08148166042698446\n",
      "epoch 5500: cost is 0.08140135836879879\n",
      "epoch 5520: cost is 0.08132132992687781\n",
      "epoch 5540: cost is 0.08124157374750415\n",
      "epoch 5560: cost is 0.08116208831866498\n",
      "epoch 5580: cost is 0.08108287198314741\n",
      "epoch 5600: cost is 0.08100392295133897\n",
      "epoch 5620: cost is 0.0809252393137314\n",
      "epoch 5640: cost is 0.08084681905312557\n",
      "epoch 5660: cost is 0.08076866005653426\n",
      "epoch 5680: cost is 0.0806907601267798\n",
      "epoch 5700: cost is 0.080613116993782\n",
      "epoch 5720: cost is 0.08053572832553202\n",
      "epoch 5740: cost is 0.08045859173874638\n",
      "epoch 5760: cost is 0.08038170480919578\n",
      "epoch 5780: cost is 0.080305065081701\n",
      "epoch 5800: cost is 0.08022867007979023\n",
      "epoch 5820: cost is 0.08015251731500883\n",
      "epoch 5840: cost is 0.08007660429587403\n",
      "epoch 5860: cost is 0.08000092853646602\n",
      "epoch 5880: cost is 0.07992548756464646\n",
      "epoch 5900: cost is 0.07985027892989517\n",
      "epoch 5920: cost is 0.07977530021075631\n",
      "epoch 5940: cost is 0.07970054902188418\n",
      "epoch 5960: cost is 0.07962602302068002\n",
      "epoch 5980: cost is 0.07955171991351065\n",
      "epoch 6000: cost is 0.07947763746150056\n",
      "epoch 6020: cost is 0.07940377348588941\n",
      "epoch 6040: cost is 0.0793301258729476\n",
      "epoch 6060: cost is 0.07925669257844341\n",
      "epoch 6080: cost is 0.07918347163165615\n",
      "epoch 6100: cost is 0.07911046113893089\n",
      "epoch 6120: cost is 0.07903765928677157\n",
      "epoch 6140: cost is 0.0789650643444709\n",
      "epoch 6160: cost is 0.07889267466627672\n",
      "epoch 6180: cost is 0.07882048869309623\n",
      "epoch 6200: cost is 0.07874850495374154\n",
      "epoch 6220: cost is 0.0786767220657216\n",
      "epoch 6240: cost is 0.07860513873558735\n",
      "epoch 6260: cost is 0.0785337537588395\n",
      "epoch 6280: cost is 0.07846256601941001\n",
      "epoch 6300: cost is 0.07839157448872991\n",
      "epoch 6320: cost is 0.07832077822439922\n",
      "epoch 6340: cost is 0.07825017636847599\n",
      "epoch 6360: cost is 0.07817976814540292\n",
      "epoch 6380: cost is 0.07810955285959321\n",
      "epoch 6400: cost is 0.07803952989269759\n",
      "epoch 6420: cost is 0.07796969870057674\n",
      "epoch 6440: cost is 0.07790005881000468\n",
      "epoch 6460: cost is 0.07783060981512946\n",
      "epoch 6480: cost is 0.077761351373719\n",
      "epoch 6500: cost is 0.07769228320322041\n",
      "epoch 6520: cost is 0.07762340507666146\n",
      "epoch 6540: cost is 0.07755471681842369\n",
      "epoch 6560: cost is 0.0774862182999161\n",
      "epoch 6580: cost is 0.07741790943517887\n",
      "epoch 6600: cost is 0.07734979017644514\n",
      "epoch 6620: cost is 0.07728186050968941\n",
      "epoch 6640: cost is 0.07721412045018913\n",
      "epoch 6660: cost is 0.07714657003812583\n",
      "epoch 6680: cost is 0.07707920933425028\n",
      "epoch 6700: cost is 0.07701203841563478\n",
      "epoch 6720: cost is 0.07694505737153456\n",
      "epoch 6740: cost is 0.07687826629937787\n",
      "epoch 6760: cost is 0.07681166530090278\n",
      "epoch 6780: cost is 0.07674525447845702\n",
      "epoch 6800: cost is 0.07667903393147477\n",
      "epoch 6820: cost is 0.07661300375314255\n",
      "epoch 6840: cost is 0.07654716402726428\n",
      "epoch 6860: cost is 0.07648151482533354\n",
      "epoch 6880: cost is 0.0764160562038195\n",
      "epoch 6900: cost is 0.0763507882016699\n",
      "epoch 6920: cost is 0.07628571083803416\n",
      "epoch 6940: cost is 0.07622082411020709\n",
      "epoch 6960: cost is 0.07615612799179172\n",
      "epoch 6980: cost is 0.0760916224310793\n",
      "epoch 7000: cost is 0.07602730734964186\n",
      "epoch 7020: cost is 0.07596318264113268\n",
      "epoch 7040: cost is 0.07589924817028787\n",
      "epoch 7060: cost is 0.07583550377212188\n",
      "epoch 7080: cost is 0.07577194925130848\n",
      "epoch 7100: cost is 0.07570858438173868\n",
      "epoch 7120: cost is 0.0756454089062456\n",
      "epoch 7140: cost is 0.07558242253648649\n",
      "epoch 7160: cost is 0.07551962495297153\n",
      "epoch 7180: cost is 0.07545701580522889\n",
      "epoch 7200: cost is 0.07539459471209523\n",
      "epoch 7220: cost is 0.07533236126212114\n",
      "epoch 7240: cost is 0.07527031501408073\n",
      "epoch 7260: cost is 0.07520845549757493\n",
      "epoch 7280: cost is 0.07514678221371848\n",
      "epoch 7300: cost is 0.07508529463590023\n",
      "epoch 7320: cost is 0.07502399221060765\n",
      "epoch 7340: cost is 0.07496287435830597\n",
      "epoch 7360: cost is 0.07490194047436331\n",
      "epoch 7380: cost is 0.0748411899300134\n",
      "epoch 7400: cost is 0.07478062207334821\n",
      "epoch 7420: cost is 0.07472023623033276\n",
      "epoch 7440: cost is 0.0746600317058356\n",
      "epoch 7460: cost is 0.07460000778466835\n",
      "epoch 7480: cost is 0.07454016373262864\n",
      "epoch 7500: cost is 0.07448049879754062\n",
      "epoch 7520: cost is 0.07442101221028875\n",
      "epoch 7540: cost is 0.07436170318583984\n",
      "epoch 7560: cost is 0.07430257092424981\n",
      "epoch 7580: cost is 0.07424361461165124\n",
      "epoch 7600: cost is 0.0741848334212187\n",
      "epoch 7620: cost is 0.07412622651410933\n",
      "epoch 7640: cost is 0.07406779304037568\n",
      "epoch 7660: cost is 0.07400953213984947\n",
      "epoch 7680: cost is 0.07395144294299401\n",
      "epoch 7700: cost is 0.07389352457172405\n",
      "epoch 7720: cost is 0.07383577614019181\n",
      "epoch 7740: cost is 0.07377819675553854\n",
      "epoch 7760: cost is 0.07372078551861051\n",
      "epoch 7780: cost is 0.07366354152463944\n",
      "epoch 7800: cost is 0.07360646386388646\n",
      "epoch 7820: cost is 0.07354955162225038\n",
      "epoch 7840: cost is 0.07349280388183943\n",
      "epoch 7860: cost is 0.07343621972150703\n",
      "epoch 7880: cost is 0.0733797982173523\n",
      "epoch 7900: cost is 0.07332353844318477\n",
      "epoch 7920: cost is 0.07326743947095461\n",
      "epoch 7940: cost is 0.07321150037114861\n",
      "epoch 7960: cost is 0.07315572021315267\n",
      "epoch 7980: cost is 0.07310009806558097\n",
      "epoch 8000: cost is 0.07304463299657368\n",
      "epoch 8020: cost is 0.07298932407406253\n",
      "epoch 8040: cost is 0.07293417036600632\n",
      "epoch 8060: cost is 0.07287917094059623\n",
      "epoch 8080: cost is 0.0728243248664324\n",
      "epoch 8100: cost is 0.07276963121267209\n",
      "epoch 8120: cost is 0.07271508904915062\n",
      "epoch 8140: cost is 0.07266069744647584\n",
      "epoch 8160: cost is 0.0726064554760965\n",
      "epoch 8180: cost is 0.07255236221034601\n",
      "epoch 8200: cost is 0.0724984167224619\n",
      "epoch 8220: cost is 0.0724446180865816\n",
      "epoch 8240: cost is 0.07239096537771587\n",
      "epoch 8260: cost is 0.07233745767169987\n",
      "epoch 8280: cost is 0.07228409404512307\n",
      "epoch 8300: cost is 0.07223087357523823\n",
      "epoch 8320: cost is 0.07217779533985053\n",
      "epoch 8340: cost is 0.0721248584171869\n",
      "epoch 8360: cost is 0.07207206188574636\n",
      "epoch 8380: cost is 0.07201940482413201\n",
      "epoch 8400: cost is 0.07196688631086498\n",
      "epoch 8420: cost is 0.07191450542418033\n",
      "epoch 8440: cost is 0.07186226124180634\n",
      "epoch 8460: cost is 0.07181015284072644\n",
      "epoch 8480: cost is 0.07175817929692474\n",
      "epoch 8500: cost is 0.07170633968511524\n",
      "epoch 8520: cost is 0.07165463307845493\n",
      "epoch 8540: cost is 0.07160305854824099\n",
      "epoch 8560: cost is 0.07155161516359214\n",
      "epoch 8580: cost is 0.0715003019911144\n",
      "epoch 8600: cost is 0.07144911809455122\n",
      "epoch 8620: cost is 0.0713980625344179\n",
      "epoch 8640: cost is 0.07134713436762036\n",
      "epoch 8660: cost is 0.0712963326470582\n",
      "epoch 8680: cost is 0.07124565642121185\n",
      "epoch 8700: cost is 0.07119510473371343\n",
      "epoch 8720: cost is 0.07114467662290157\n",
      "epoch 8740: cost is 0.07109437112135934\n",
      "epoch 8760: cost is 0.07104418725543535\n",
      "epoch 8780: cost is 0.07099412404474727\n",
      "epoch 8800: cost is 0.07094418050166781\n",
      "epoch 8820: cost is 0.07089435563079202\n",
      "epoch 8840: cost is 0.07084464842838564\n",
      "epoch 8860: cost is 0.07079505788181424\n",
      "epoch 8880: cost is 0.0707455829689514\n",
      "epoch 8900: cost is 0.07069622265756645\n",
      "epoch 8920: cost is 0.0706469759046898\n",
      "epoch 8940: cost is 0.07059784165595565\n",
      "epoch 8960: cost is 0.07054881884492079\n",
      "epoch 8980: cost is 0.07049990639235834\n",
      "epoch 9000: cost is 0.07045110320552563\n",
      "epoch 9020: cost is 0.07040240817740455\n",
      "epoch 9040: cost is 0.07035382018591327\n",
      "epoch 9060: cost is 0.07030533809308785\n",
      "epoch 9080: cost is 0.07025696074423235\n",
      "epoch 9100: cost is 0.07020868696703536\n",
      "epoch 9120: cost is 0.07016051557065196\n",
      "epoch 9140: cost is 0.07011244534474846\n",
      "epoch 9160: cost is 0.07006447505850841\n",
      "epoch 9180: cost is 0.07001660345959784\n",
      "epoch 9200: cost is 0.0699688292730873\n",
      "epoch 9220: cost is 0.06992115120032825\n",
      "epoch 9240: cost is 0.06987356791778172\n",
      "epoch 9260: cost is 0.06982607807579604\n",
      "epoch 9280: cost is 0.06977868029733139\n",
      "epoch 9300: cost is 0.06973137317662782\n",
      "epoch 9320: cost is 0.06968415527781364\n",
      "epoch 9340: cost is 0.06963702513345106\n",
      "epoch 9360: cost is 0.06958998124301552\n",
      "epoch 9380: cost is 0.0695430220713047\n",
      "epoch 9400: cost is 0.0694961460467738\n",
      "epoch 9420: cost is 0.06944935155979282\n",
      "epoch 9440: cost is 0.06940263696082119\n",
      "epoch 9460: cost is 0.06935600055849564\n",
      "epoch 9480: cost is 0.0693094406176265\n",
      "epoch 9500: cost is 0.06926295535709709\n",
      "epoch 9520: cost is 0.06921654294766123\n",
      "epoch 9540: cost is 0.06917020150963357\n",
      "epoch 9560: cost is 0.06912392911046628\n",
      "epoch 9580: cost is 0.06907772376220717\n",
      "epoch 9600: cost is 0.06903158341883203\n",
      "epoch 9620: cost is 0.06898550597344554\n",
      "epoch 9640: cost is 0.06893948925534327\n",
      "epoch 9660: cost is 0.06889353102692879\n",
      "epoch 9680: cost is 0.06884762898047804\n",
      "epoch 9700: cost is 0.06880178073474415\n",
      "epoch 9720: cost is 0.06875598383139499\n",
      "epoch 9740: cost is 0.06871023573127642\n",
      "epoch 9760: cost is 0.06866453381049328\n",
      "epoch 9780: cost is 0.06861887535630096\n",
      "epoch 9800: cost is 0.0685732575627998\n",
      "epoch 9820: cost is 0.06852767752642586\n",
      "epoch 9840: cost is 0.06848213224123013\n",
      "epoch 9860: cost is 0.06843661859394112\n",
      "epoch 9880: cost is 0.06839113335880395\n",
      "epoch 9900: cost is 0.06834567319219187\n",
      "epoch 9920: cost is 0.06830023462698612\n",
      "epoch 9940: cost is 0.0682548140667219\n",
      "epoch 9960: cost is 0.06820940777949963\n",
      "epoch 9980: cost is 0.0681640118916634\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet(\n",
    "    X=X_train,\n",
    "    y=y_train\n",
    ")\n",
    "costs = net.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "528a6490-0faa-49ea-b2e1-37f5f50ef7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8a5efcded0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7260f7-0a08-40e3-8305-c39f19f60a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net: NeuralNet, X, y):\n",
    "    y_hat = net.forward(X)\n",
    "    prediction = np.round(y_hat).astype(int).reshape(-1)\n",
    "    m = y_hat.reshape(-1).shape[0]\n",
    "    num_correct = np.where(prediction == y)[0].shape[0]\n",
    "    print(f\"got {num_correct}/{m} correct\")\n",
    "    \n",
    "    predictionFrame = pd.DataFrame(\n",
    "            data=np.hstack([prediction.reshape(m, -1), y_hat.reshape(m, -1), y.reshape(m, -1)]),\n",
    "            columns=[\"predicted\", \"y_hat\", \"actual\"]\n",
    "      )\n",
    "    return predictionFrame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8e20edf-11d3-419c-815f-30ab3124c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 48/61 correct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988272</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977814</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326352</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058659</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted     y_hat  actual\n",
       "0         1.0  0.988272     1.0\n",
       "1         0.0  0.038224     0.0\n",
       "2         0.0  0.007500     0.0\n",
       "3         0.0  0.006754     0.0\n",
       "4         1.0  0.977814     1.0\n",
       "..        ...       ...     ...\n",
       "56        0.0  0.025418     1.0\n",
       "57        1.0  0.976286     1.0\n",
       "58        1.0  0.831196     0.0\n",
       "59        0.0  0.326352     1.0\n",
       "60        0.0  0.058659     1.0\n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(net, X_test.T, y_test) # expects X to be n x m matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bded413-c441-45f9-84e5-9497323428bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
